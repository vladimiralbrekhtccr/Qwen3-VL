{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f817720b-b362-4bad-8187-d6af2b7ddae6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# text inferencerequest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea23a84-4d12-4261-99e3-fa27d868096a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import openai\n",
    "\n",
    "client = openai.Client(\n",
    "    base_url=\"http://localhost:6655/v1\", api_key=\"EMPTY\"\n",
    ")\n",
    "MODEL = \"ki_oylan_a_v_t_2_5\"\n",
    "\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Ты любишь смотреть аниме. /no_think\"},\n",
    "        {\"role\": \"user\", \"content\": \"Какое у тебя любимое аниме?\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    "    max_tokens=256,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "first_token_time = None\n",
    "for chunk in response:\n",
    "    if chunk.choices[0].delta.content is not None:\n",
    "        if first_token_time is None:  # first token arrived\n",
    "            first_token_time = time.perf_counter()\n",
    "            ttft = first_token_time - start_time\n",
    "            print(f\"\\n\\nTTFT: {ttft:.3f} seconds\\n\")\n",
    "        print(chunk.choices[0].delta.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c239556-8d87-4fbc-9ee7-dade2e7720f4",
   "metadata": {},
   "source": [
    "# image inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ae199c8-426a-46e1-8835-27b56d6e9b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "TTFT: 5.454 seconds\n",
      "\n",
      "This is a screenshot of a GitHub repository page for a project named `pytorch-stable-diffusion`. The repository is public, as indicated by the \"Public\" label next to the name.\n",
      "\n",
      "### Repository Overview\n",
      "- **Name:** `pytorch-stable-diffusion`\n",
      "- **Status:** Public\n",
      "- **Branch:** The current branch is `main`.\n",
      "- **Branches:** There is 1 branch in total.\n",
      "- **Tags:** There are 0 tags.\n",
      "- **Watchers:** 11 users are watching the repository.\n",
      "- **Forks:** The repository has been forked 182 times.\n",
      "- **Actions:** The user can \"Watch,\" \"Open in GitIngest,\" or \"Fork\" the repository.\n",
      "\n",
      "### Recent Activity\n",
      "The most recent activity shown is a merge pull request:\n",
      "- **Author:** `hkproj`\n",
      "- **Pull Request:** `#25` from the branch `aksj98/main`.\n",
      "- **Commit Hash:** `6e69000`\n",
      "- **Date:** 10 months ago.\n",
      "- **Commits:** This merge introduced 21 commits.\n",
      "\n",
      "### Repository Contents\n",
      "The main file list displays the following items:\n",
      "\n",
      "- **Folder:** `sd` - This is"
     ]
    }
   ],
   "source": [
    "# Image inference\n",
    "import time\n",
    "from pathlib import Path\n",
    "import openai\n",
    "import base64\n",
    "client = openai.Client(\n",
    "    base_url=\"http://localhost:6655/v1\", api_key=\"EMPTY\"\n",
    ")\n",
    "MODEL = \"ki_l\"\n",
    "\n",
    "# ########################################################################\n",
    "# ################ if you want to use local file #########################\n",
    "# ########################################################################\n",
    "# IMAGE_PATH = Path(\"/home/vladimir_albrekht/projects/digital_bridge/vllm/1_vladimir_utils/utils/benchs_perf/assets/cute_girl.jpg\")\n",
    "\n",
    "\n",
    "# def guess_mime(path: Path) -> str:\n",
    "#     \"\"\"Guess MIME type from file extension\"\"\"\n",
    "#     ext = path.suffix.lower()\n",
    "#     if ext in [\".jpg\", \".jpeg\"]:\n",
    "#         return \"image/jpeg\"\n",
    "#     elif ext == \".png\":\n",
    "#         return \"image/png\"\n",
    "#     elif ext == \".webp\":\n",
    "#         return \"image/webp\"\n",
    "#     elif ext == \".gif\":\n",
    "#         return \"image/gif\"\n",
    "#     else:\n",
    "#         return \"image/jpeg\"  # Fallback\n",
    "\n",
    "# def encode_image(image_path: Path) -> str:\n",
    "#     \"\"\"Encode image file to base64 string\"\"\"\n",
    "#     return base64.b64encode(image_path.read_bytes()).decode(\"utf-8\")\n",
    "\n",
    "# base64_image = encode_image(IMAGE_PATH)\n",
    "# mime_type = guess_mime(IMAGE_PATH)\n",
    "# # data:{mime_type};base64,{base64_image}\n",
    "# ########################################################################\n",
    "\n",
    "\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "response = client.chat.completions.create(\n",
    "  model=MODEL,\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"Describe this image in detail\", # make sure to inclue <image> otherwise it will crush.\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\":  f\"https://huggingface.co/datasets/CCRss/kv_brain/resolve/main/Xnip2025-08-24_15-02-37.jpg\" # for local path `data:{mime_type};base64,{base64_image}`\n",
    "          },\n",
    "        },\n",
    "      ],\n",
    "    }\n",
    "  ],\n",
    "  max_tokens=256,\n",
    "  stream=True,\n",
    "  temperature=0.1\n",
    ")\n",
    "\n",
    "\n",
    "first_token_time = None\n",
    "for chunk in response:\n",
    "    if chunk.choices[0].delta.content is not None:\n",
    "        if first_token_time is None:  # first token arrived\n",
    "            first_token_time = time.perf_counter()\n",
    "            ttft = first_token_time - start_time\n",
    "            print(f\"\\n\\nTTFT: {ttft:.3f} seconds\\n\")\n",
    "        print(chunk.choices[0].delta.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707ec328-413b-4429-a085-782bcef370c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "0_9_2_vllm_oylan_2_5",
   "language": "python",
   "name": "0_9_2_vllm_oylan_2_5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
